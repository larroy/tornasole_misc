{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import boto3\n",
    "import pytest\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import Rule, DebuggerHookConfig, TensorBoardOutputConfig, CollectionConfig, rule_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::926857016169:role/pllarroy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'random_seed': True, 'num_steps': 50, 'epochs': 5,\n",
    "                   'data_dir':'/tmp/pytorch-smdebug'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing())\n",
    "]\n",
    "\n",
    "estimator = PyTorch(\n",
    "                  entry_point='train.py',\n",
    "                  role=role,\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='local',\n",
    "                  train_volume_size=400,\n",
    "                  train_max_run=3600,\n",
    "                  hyperparameters=hyperparameters,\n",
    "                  framework_version='1.3.1',\n",
    "                  py_version='py3',\n",
    "                  rules = rules\n",
    "                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmprmjgokvr_algo-1-prn7w_1 ... \n",
      "\u001b[1BAttaching to tmprmjgokvr_algo-1-prn7w_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:21,618 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:21,621 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:21,635 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:21,644 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:22,048 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:22,048 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:22,049 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:22,049 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m /opt/conda/bin/python -m pip install . \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Processing /tmp/tmpssob36yk/module_dir\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Building wheels for collected packages: default-user-module-name\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   Building wheel for default-user-module-name (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \u001b[?25h  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=10040 sha256=732cea1388238eb490f0d77bcae531d0f09f0be06a5a033864f03480f7c8a532\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-_t7v6g3j/wheels/ef/25/4b/d78b0d04239fff887e976f422943f8e188b56031b739b37034\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Successfully built default-user-module-name\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Installing collected packages: default-user-module-name\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Successfully installed default-user-module-name-1.0.0\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.1; however, version 20.0.2 is available.\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:24,717 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:24,737 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:24,755 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:24,770 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"current_host\": \"algo-1-prn7w\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m         \"algo-1-prn7w\"\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m         \"random_seed\": true,\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m         \"num_steps\": 50,\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m         \"epochs\": 5,\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m         \"data_dir\": \"/tmp/pytorch-smdebug\"\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"job_name\": \"pytorch-training-2020-03-04-01-11-16-219\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"master_hostname\": \"algo-1-prn7w\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-west-2-926857016169/pytorch-training-2020-03-04-01-11-16-219/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m         \"current_host\": \"algo-1-prn7w\",\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m             \"algo-1-prn7w\"\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_HOSTS=[\"algo-1-prn7w\"]\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_HPS={\"data_dir\":\"/tmp/pytorch-smdebug\",\"epochs\":5,\"num_steps\":50,\"random_seed\":true}\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-prn7w\",\"hosts\":[\"algo-1-prn7w\"]}\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_CURRENT_HOST=algo-1-prn7w\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-west-2-926857016169/pytorch-training-2020-03-04-01-11-16-219/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-prn7w\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-prn7w\"],\"hyperparameters\":{\"data_dir\":\"/tmp/pytorch-smdebug\",\"epochs\":5,\"num_steps\":50,\"random_seed\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-03-04-01-11-16-219\",\"log_level\":20,\"master_hostname\":\"algo-1-prn7w\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-926857016169/pytorch-training-2020-03-04-01-11-16-219/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-prn7w\",\"hosts\":[\"algo-1-prn7w\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_USER_ARGS=[\"--data_dir\",\"/tmp/pytorch-smdebug\",\"--epochs\",\"5\",\"--num_steps\",\"50\",\"--random_seed\",\"True\"]\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_HP_RANDOM_SEED=true\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_HP_NUM_STEPS=50\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_HP_EPOCHS=5\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m SM_HP_DATA_DIR=/tmp/pytorch-smdebug\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m /opt/conda/bin/python train.py --data_dir /tmp/pytorch-smdebug --epochs 5 --num_steps 50 --random_seed True\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Create neural network module\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m INFO:__main__:Create neural network module\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"train.py\", line 195, in <module>\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     main()\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"train.py\", line 187, in main\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     hook = create_smdebug_hook()\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"train.py\", line 121, in create_smdebug_hook\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     hook = smd.Hook.create_from_json_file()\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"/opt/conda/lib/python3.6/site-packages/smdebug/core/hook.py\", line 248, in create_from_json_file\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     return create_hook_from_json_config(cls, json_config_path=json_file_path)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"/opt/conda/lib/python3.6/site-packages/smdebug/core/json_config.py\", line 212, in create_hook_from_json_config\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     params_dict = get_json_config_as_dict(json_config_path=json_config_path)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"/opt/conda/lib/python3.6/site-packages/smdebug/core/json_config.py\", line 88, in get_json_config_as_dict\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     with open(path) as json_config_file:\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/config/debughookconfig.json'\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m 2020-03-04 01:11:26,875 sagemaker-containers ERROR    ExecuteUserScriptError:\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Command \"/opt/conda/bin/python train.py --data_dir /tmp/pytorch-smdebug --epochs 5 --num_steps 50 --random_seed True\"\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m INFO:__main__:Create neural network module\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"train.py\", line 195, in <module>\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     main()\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"train.py\", line 187, in main\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     hook = create_smdebug_hook()\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"train.py\", line 121, in create_smdebug_hook\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     hook = smd.Hook.create_from_json_file()\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"/opt/conda/lib/python3.6/site-packages/smdebug/core/hook.py\", line 248, in create_from_json_file\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     return create_hook_from_json_config(cls, json_config_path=json_file_path)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"/opt/conda/lib/python3.6/site-packages/smdebug/core/json_config.py\", line 212, in create_hook_from_json_config\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     params_dict = get_json_config_as_dict(json_config_path=json_config_path)\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m   File \"/opt/conda/lib/python3.6/site-packages/smdebug/core/json_config.py\", line 88, in get_json_config_as_dict\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m     with open(path) as json_config_file:\n",
      "\u001b[36malgo-1-prn7w_1  |\u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/config/debughookconfig.json'\n",
      "\u001b[36mtmprmjgokvr_algo-1-prn7w_1 exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/tmp/tmprmjgokvr/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/devel/tornasole/sagemaker-python-sdk/src/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/tornasole/sagemaker-python-sdk/src/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-91719653cf32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/devel/tornasole/sagemaker-python-sdk/src/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/tornasole/sagemaker-python-sdk/src/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/tornasole/sagemaker-python-sdk/src/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     def process(\n",
      "\u001b[0;32m~/devel/tornasole/sagemaker-python-sdk/src/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtraining_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalTrainingJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/tornasole/sagemaker-python-sdk/src/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/tornasole/sagemaker-python-sdk/src/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/tmp/tmprmjgokvr/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = estimator.latest_job_debugger_artifacts_path()\n",
    "print('Tensors are stored in: {}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.latest_training_job.rule_job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "path = estimator.latest_job_debugger_artifacts_path()\n",
    "trial = create_trial(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Party\n",
    "from smdebug import modes\n",
    "from smdebug.analysis.utils import parse_bool, parse_list_from_str\n",
    "from smdebug.core.modes import ALLOWED_MODE_NAMES\n",
    "from smdebug.rules.rule import Rule\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "class LossNotDecreasing(Rule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_trial,\n",
    "        collection_names=None,\n",
    "        tensor_regex=None,\n",
    "        use_losses_collection=True,\n",
    "        num_steps=10,\n",
    "        diff_percent=0.1,\n",
    "        increase_threshold_percent=5.0,\n",
    "        mode=None,\n",
    "        absolute_val=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This rule helps you identify if you are running into a situation\n",
    "        where loss is not going down fast enough as termed by diff_percent or\n",
    "        loss has increased by increase_threshold_percent.\n",
    "        Note that if loss tensor is not scalar, mean is calculated for loss tensor to convert it to scalar.\n",
    "\n",
    "        :param base_trial: the trial whose execution will invoke the rule\n",
    "        :param collection_names: List of str representing collection names.\n",
    "              The tensors belonging to these collections will be considered.\n",
    "              Note that only scalar tensors will be picked.\n",
    "        :param tensor_regex: List of str representing regex patterns.\n",
    "              The tensors matching these patterns will be considered.\n",
    "              If both collection_names and tensor_regex are specified,\n",
    "              the rule will check for union of tensors.\n",
    "              Note that only scalar tensors will be picked.\n",
    "        :param use_losses_collection: bool\n",
    "              Tries to use the collection 'losses' to fetch the losses\n",
    "        :param num_steps: int\n",
    "              The minimum number of steps after which\n",
    "              we want which we check if the loss has decreased.\n",
    "              The rule evaluation happens every num_steps, and\n",
    "              the rule checks the loss for this step with the loss at the\n",
    "              newest step which is at least num_steps behind the current step.\n",
    "              For example, if the loss is being saved every 4 steps and steps saved are 0,4,8,12,16,20,24,28,32,36\n",
    "              but num_steps is 10. First invocation will happen at step 12 and loss at step 12 is compared to loss at step 0\n",
    "              Next invocation would happen at step:24(since 10 steps after 12 would be 22 and there is no 22 && 23) and loss at step:24 is compared with loss at step 12\n",
    "              Next invocation would happen at step:36(since 10 steps after 24 would be 34 and there is no 34 && 35) and loss at step:36 is compared with loss at step 24\n",
    "              Default: 10\n",
    "        :param diff_percent: float\n",
    "            The minimum difference in percentage that loss should be lower by.\n",
    "            By default, the rule just checks if loss is going down.\n",
    "            If you want to specify a stricter check that loss is\n",
    "            going down fast enough, you might want to pass diff_percent. Default: 0.1\n",
    "        :param increase_threshold_percent: float\n",
    "            The maximum threshold percent that loss is allowed to increase in case loss has been\n",
    "            increasing. Default: 5\n",
    "        :param mode: string\n",
    "            name of mode to query tensor values for rule checking.\n",
    "            If this is not passed, the rule checks for GLOBAL mode. Allowed values are TRAIN, EVAL, GLOBAL\n",
    "            Default: GLOBAL\n",
    "        :param absolute_val: string\n",
    "            If this is False, rule checks for original values of loss tensors. By default: rule checks if absolute loss is decreasing or not\n",
    "            Default: True\n",
    "        \"\"\"\n",
    "        super().__init__(base_trial)\n",
    "        self.tensor_regex = parse_list_from_str(tensor_regex)\n",
    "        self.collection_names = parse_list_from_str(collection_names)\n",
    "        self.use_losses_collection = parse_bool(use_losses_collection, True)\n",
    "        self.num_steps = int(num_steps)\n",
    "        self._set_mode(mode)\n",
    "        self._set_min_diff(diff_percent)\n",
    "        self._load_tensor_names()\n",
    "\n",
    "        self.last_evaluated_step = None\n",
    "        self.increase_threshold_percent = float(increase_threshold_percent)\n",
    "        self.absolute_val = parse_bool(absolute_val, True)\n",
    "        self.logger.info(\n",
    "            \"LossNotDecreasing rule created with num_steps: {},\"\n",
    "            \" diff_percent: {}, increase_threshold_percent: {}, mode: {}, tensor_regex: {}, \"\n",
    "            \"collection_names: {} absolute_val:{}\".format(\n",
    "                self.num_steps,\n",
    "                self.min_diff_percent,\n",
    "                self.increase_threshold_percent,\n",
    "                self.mode.name,\n",
    "                \",\".join(self.tensor_regex),\n",
    "                \",\".join(self.collection_names),\n",
    "                self.absolute_val,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _set_min_diff(self, min_diff_percent):\n",
    "        if min_diff_percent is not None:\n",
    "            self.min_diff_percent = float(min_diff_percent)\n",
    "        else:\n",
    "            self.min_diff_percent = 0.0\n",
    "        if self.min_diff_percent < 0.0 or self.min_diff_percent > 100.0:\n",
    "            raise SageMakerDebuggerRuleConfigValidationError(\n",
    "                self.rule_name,\n",
    "                \"diff_percent {} has to be between 0.0 and 100.0\".format(self.min_diff_percent),\n",
    "            )\n",
    "\n",
    "    def _set_mode(self, mode):\n",
    "        if mode is None:\n",
    "            self.mode = modes.GLOBAL\n",
    "        elif mode in ALLOWED_MODE_NAMES:\n",
    "            self.mode = modes[mode]\n",
    "        else:\n",
    "            raise SageMakerDebuggerRuleConfigValidationError(\n",
    "                self.rule_name, \"mode can only be one of {}\".format(\",\".join(ALLOWED_MODE_NAMES))\n",
    "            )\n",
    "\n",
    "    def _load_tensor_names(self):\n",
    "        self.tensor_names = set()\n",
    "\n",
    "        if self.use_losses_collection and \"losses\" not in self.collection_names:\n",
    "            self.collection_names.append(\"losses\")\n",
    "\n",
    "        for cname in self.collection_names:\n",
    "            try:\n",
    "                c = self.base_trial.collection(cname)\n",
    "                tn = c.tensor_names\n",
    "                self.tensor_names.update(tn)\n",
    "            except KeyError:\n",
    "                self.logger.info(\"Could not find collection {}\".format(cname))\n",
    "\n",
    "        if not len(self.tensor_regex) and not len(self.tensor_names):\n",
    "            self.tensor_regex.append(\"loss\")\n",
    "\n",
    "    def _update_tensor_names(self):\n",
    "        for tname in self.base_trial.tensor_names(regex=self.tensor_regex):\n",
    "            self.tensor_names.add(tname)\n",
    "\n",
    "    def _get_prev_global_step(self, prev_mode_steps, curr_mode_step):\n",
    "        # now go and find the last step\n",
    "        # which is at least num_steps behind\n",
    "        if len(prev_mode_steps) > 0:\n",
    "            last_step = prev_mode_steps[-1]\n",
    "            if last_step == curr_mode_step:\n",
    "                for prev_mode_step in reversed(prev_mode_steps):\n",
    "                    step_diff = curr_mode_step - prev_mode_step\n",
    "                    if step_diff >= self.num_steps:\n",
    "                        prev_global_step = self.base_trial.global_step(\n",
    "                            mode=self.mode, mode_step=prev_mode_step\n",
    "                        )\n",
    "                        return prev_global_step\n",
    "        return None\n",
    "\n",
    "    def set_required_tensors(self, step):\n",
    "        # we call this on every step as there may be\n",
    "        # new tensors after some steps\n",
    "        # since we are querying tensors by regex\n",
    "        self._update_tensor_names()\n",
    "        # for every num_steps\n",
    "        if self.last_evaluated_step is None or self.last_evaluated_step + self.num_steps <= step:\n",
    "            # get mode and mode_step for the current step\n",
    "            curr_mode, curr_mode_step = self.base_trial.mode_modestep(step)\n",
    "            self.logger.debug(\n",
    "                \"Current mode is: {} and mode_step is {} \".format(curr_mode, curr_mode_step)\n",
    "            )\n",
    "            if curr_mode == self.mode:\n",
    "                for tname in self.tensor_names:\n",
    "                    # get steps before mode_step in the current mode\n",
    "                    prev_mode_steps = self.base_trial.tensor(tname).prev_steps(\n",
    "                        curr_mode_step, mode=self.mode\n",
    "                    )\n",
    "                    self.logger.debug(\n",
    "                        \"tname:{} Previous mode steps :{}\".format(tname, prev_mode_steps)\n",
    "                    )\n",
    "                    prev_global_step = self._get_prev_global_step(prev_mode_steps, curr_mode_step)\n",
    "                    self.logger.debug(\"Previous global step:{}\".format(prev_global_step))\n",
    "                    if prev_global_step is not None:\n",
    "                        steps = [prev_global_step, step]\n",
    "                        self.logger.info(\n",
    "                            \"Adding tname:{} and steps:{} to req_tensors\".format(tname, steps)\n",
    "                        )\n",
    "                        self.req_tensors.add(tname, steps=steps)\n",
    "\n",
    "    def _add_failed_tname(self, failed_tnames, tname, step, old_val, new_val):\n",
    "        self.logger.info(\n",
    "            \"Loss {} is not decreasing over the last {} steps \"\n",
    "            \"at step {}. It was {} and now is {}\".format(\n",
    "                tname, self.num_steps, step, old_val, new_val\n",
    "            )\n",
    "        )\n",
    "        failed_tnames.append(tname)\n",
    "        return failed_tnames\n",
    "\n",
    "    def invoke_at_step(self, step):\n",
    "        failed_tnames = []\n",
    "        for tensor in self.req_tensors.get():\n",
    "            steps = self.req_tensors.get_tensor_steps(tensor.name)\n",
    "            self.logger.info(\n",
    "                \"Checking loss values(tensor_name:{}) at step:{} and step:{} \".format(\n",
    "                    tensor.name, steps[0], steps[1]\n",
    "                )\n",
    "            )\n",
    "            old_val = tensor.value(steps[0])\n",
    "            new_val = tensor.value(steps[1])\n",
    "            if old_val.size != 1:\n",
    "                old_val = np.ones(shape=(1,)) * np.mean(old_val)\n",
    "                self.logger.info(\"Calculated mean:{} from old_val loss vector\".format(old_val[0]))\n",
    "            if new_val.size != 1:\n",
    "                new_val = np.ones(shape=(1,)) * np.mean(new_val)\n",
    "                self.logger.info(\"Calculated mean:{} from new_val loss vector\".format(new_val[0]))\n",
    "            if old_val.size == 1 and new_val.size == 1:\n",
    "                if self.absolute_val:\n",
    "                    old_val = abs(float(old_val[0]))\n",
    "                    new_val = abs(float(new_val[0]))\n",
    "                else:\n",
    "                    old_val = float(old_val[0])\n",
    "                    new_val = float(new_val[0])\n",
    "\n",
    "                min_decreased_loss_allowed = old_val - old_val * (self.min_diff_percent / 100.0)\n",
    "                max_increased_loss_allowed = old_val + old_val * (\n",
    "                    self.increase_threshold_percent / 100.0\n",
    "                )\n",
    "                diff = old_val - new_val\n",
    "                if diff >= 0 and new_val > min_decreased_loss_allowed + sys.float_info.epsilon:\n",
    "                    self.logger.info(\n",
    "                        \"Loss is not decreasing fast enough, diff is:{} , abs_old_val:{} , abs_new_val:{} min_required_change_percent:{} min_decreased_loss_allowed:{}\".format(\n",
    "                            diff,\n",
    "                            old_val,\n",
    "                            new_val,\n",
    "                            self.min_diff_percent,\n",
    "                            min_decreased_loss_allowed,\n",
    "                        )\n",
    "                    )\n",
    "                    self._add_failed_tname(failed_tnames, tensor.name, step, old_val, new_val)\n",
    "                elif diff < 0 and new_val > max_increased_loss_allowed + sys.float_info.epsilon:\n",
    "                    self.logger.info(\n",
    "                        \"Loss is increasing and breached increase_threshold_percent:{}, diff is:{} , abs_old_val:{} , abs_new_val:{} , max_increased_loss_allowed:{} \".format(\n",
    "                            self.increase_threshold_percent,\n",
    "                            diff,\n",
    "                            old_val,\n",
    "                            new_val,\n",
    "                            max_increased_loss_allowed,\n",
    "                        )\n",
    "                    )\n",
    "                    self._add_failed_tname(failed_tnames, tensor.name, step, old_val, new_val)\n",
    "                self.logger.info(\n",
    "                    \"loss_mode:{} step:{} loss_value:{} previous_step:{} previous_loss_value:{} min_decreased_loss_allowed:{} , max_increased_loss_allowed:{}\".format(\n",
    "                        self.mode,\n",
    "                        steps[1],\n",
    "                        new_val,\n",
    "                        steps[0],\n",
    "                        old_val,\n",
    "                        min_decreased_loss_allowed,\n",
    "                        max_increased_loss_allowed,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                self.logger.warning(\n",
    "                    \"Tensor {} was not a scalar or 1-D array as expected at the \"\n",
    "                    \"steps {}\".format(tensor.name, \",\".join(steps))\n",
    "                )\n",
    "\n",
    "        if len(self.req_tensors.get_names()):\n",
    "            self.last_evaluated_step = step\n",
    "\n",
    "        if failed_tnames:\n",
    "            message = \"{} {} not decreasing over the last {} steps at step {}\"\n",
    "            s = \"losses are \" if len(failed_tnames) > 1 else \"loss is\"\n",
    "            self.logger.info(message.format(len(failed_tnames), s, self.num_steps, step))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.rules.rule_invoker import invoke_rule\n",
    "\n",
    "rule = LossNotDecreasing(trial, tensor_regex=\"CrossEntropyLoss_output_0\", mode=\"TRAIN\")\n",
    "invoke_rule(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
